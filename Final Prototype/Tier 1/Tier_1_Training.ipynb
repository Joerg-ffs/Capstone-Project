{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install PyDrive to enable file download and upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ow-HcBjaAcep"
   },
   "outputs": [],
   "source": [
    "!pip install PyDrive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UrM28eOSjUb4"
   },
   "source": [
    "Importing google specific libraries as well as authenticating the current user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7EHMrX7tAwLa"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pxd1ovkdjQPA"
   },
   "source": [
    "Downloading the image training data folder from google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fi3FI6ojBSKL"
   },
   "outputs": [],
   "source": [
    "download = drive.CreateFile({'id': '1ZrqJtPqAVVuZAycNJN9hl2rEKFiiJ80-'})\n",
    "download.GetContentFile('frames.tar.7z')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z6x6tr3BjM97"
   },
   "source": [
    "Unzipping img folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w3zF2OYv_3pa"
   },
   "outputs": [],
   "source": [
    "!apt-get install p7zip-full\n",
    "!p7zip -d frames.tar.7z\n",
    "!tar -xvf frames.tar!7z e frames.7z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WzPXQbuHKD2g"
   },
   "source": [
    "Getting the file from the tar ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U0TuDXREJ_Q2"
   },
   "outputs": [],
   "source": [
    "!tar -xvf frames.tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LWVzdMwjjH6T"
   },
   "source": [
    "Process data to be ready for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kX63WgCZLfDs"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageEnhance\n",
    "\n",
    "\n",
    "features_directory = './data/'\n",
    "labels_file = 'driving_log.csv'\n",
    "\n",
    "\n",
    "def data_loading():\n",
    "    logs = []\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    #creates datafram from csv file holding angle and image path values\n",
    "    data = pd.read_csv(\"driving_log.csv\")\n",
    "    \n",
    "    #Creates arrays from the angle and image columns\n",
    "    data_img = np.array(data['Image']) \n",
    "    data_img = data_img.reshape(-1, 1)                                                 \n",
    "    data_angle = np.array(data['Angle'])                                              \n",
    "    data_angle = data_angle.reshape(-1, 1)\n",
    "    \n",
    "    i = 0\n",
    "    sum_angle = 0\n",
    "    \n",
    "    #loops through each image in array\n",
    "    for j in data_img:\n",
    "        \n",
    "        #gets angle and image path from array\n",
    "        angle = data_angle[i]            \n",
    "        img_string = str(data_img[i,0])\n",
    "        img_string = img_string[4:]\n",
    "        \n",
    "        #reads image and resizes it from 400x300 to 200x66\n",
    "        img_array = cv2.imread('frames/' + img_string, 3) \n",
    "        img_array = img_array[80:212,0:400]\n",
    "        img_array = cv2.resize(img_array, (200,66))\n",
    "        \n",
    "        #Checks past 10 angles, if average is very small, don't include in final array\n",
    "        sum_angle += abs(angle)                        \n",
    "        if sum_angle > 0.15:\n",
    "          features.append(img_array)\n",
    "          labels.append(angle)\n",
    "        if i % 10 == 0:\n",
    "          sum_angle = 0\n",
    "        \n",
    "        #adds additional instances of bigger angles to help make dataset more uniform\n",
    "        if abs(angle < 0.25) and abs(angle > 0.1):\n",
    "            features.append(cv2.flip(img_array, 1))\n",
    "            labels.append(angle*(-1))\n",
    "            features.append(img_array)\n",
    "            labels.append(angle)\n",
    "            features.append(cv2.flip(img_array, 1))\n",
    "            labels.append(angle*(-1))\n",
    "            features.append(img_array)\n",
    "            labels.append(angle)\n",
    "            features.append(cv2.flip(img_array, 1))\n",
    "            labels.append(angle*(-1))\n",
    "            features.append(img_array)\n",
    "            labels.append(angle)\n",
    "            features.append(cv2.flip(img_array, 1))\n",
    "            labels.append(angle*(-1))\n",
    "            features.append(img_array)\n",
    "            labels.append(angle)\n",
    "          \n",
    "        if abs(angle > 0.25):\n",
    "            features.append(cv2.flip(img_array, 1))\n",
    "            labels.append(angle*(-1))\n",
    "            features.append(img_array)\n",
    "            labels.append(angle)\n",
    "            features.append(cv2.flip(img_array, 1))\n",
    "            labels.append(angle*(-1))\n",
    "            features.append(img_array)\n",
    "            labels.append(angle)\n",
    "            features.append(cv2.flip(img_array, 1))\n",
    "            labels.append(angle*(-1))\n",
    "            features.append(img_array)\n",
    "            labels.append(angle)\n",
    "            features.append(cv2.flip(img_array, 1))\n",
    "            labels.append(angle*(-1))\n",
    "            features.append(img_array)\n",
    "            labels.append(angle) \n",
    "        \n",
    "        if abs(angle) < 1 and abs(angle) > 0.25:\n",
    "            features.append(cv2.flip(img_array, 1))\n",
    "            labels.append(angle*(-1))\n",
    "            features.append(img_array)\n",
    "            labels.append(angle)\n",
    "            features.append(cv2.flip(img_array, 1))\n",
    "            labels.append(angle*(-1))\n",
    "            features.append(img_array)\n",
    "            labels.append(angle)\n",
    "            features.append(cv2.flip(img_array, 1))\n",
    "            labels.append(angle*(-1))\n",
    "            features.append(img_array)\n",
    "            labels.append(angle)\n",
    "            features.append(cv2.flip(img_array, 1))\n",
    "            labels.append(angle*(-1))\n",
    "            features.append(img_array)\n",
    "            labels.append(angle)\n",
    "        if abs(angle > 0.5):\n",
    "            features.append(cv2.flip(img_array, 1))\n",
    "            labels.append(angle*(-1))\n",
    "            features.append(img_array)\n",
    "            labels.append(angle)\n",
    "            features.append(cv2.flip(img_array, 1))\n",
    "            labels.append(angle*(-1))\n",
    "            features.append(img_array)\n",
    "            labels.append(angle)\n",
    "            features.append(cv2.flip(img_array, 1))\n",
    "            labels.append(angle*(-1))\n",
    "            features.append(img_array)\n",
    "            labels.append(angle)\n",
    "            features.append(cv2.flip(img_array, 1))\n",
    "            labels.append(angle*(-1))\n",
    "            features.append(img_array)\n",
    "            labels.append(angle)\n",
    "            \n",
    "        i = i + 1     \n",
    "    return features, labels\n",
    "       \n",
    "#gets final array from data loading function\n",
    "features, labels = data_loading()\n",
    "\n",
    "features = np.array(features).astype('float32')\n",
    "labels = np.array(labels).astype('float32')\n",
    "\n",
    "#plots a histogram of data to show distribution\n",
    "plt.hist(labels, bins=20)\n",
    "plt.show()\n",
    "\n",
    "#Prints how many data points there are in final array\n",
    "print(len(features))\n",
    "\n",
    "#Saves final arrays to pickles\n",
    "with open(\"features\", \"wb\") as f:\n",
    "    pickle.dump(features, f, protocol=4)\n",
    "with open(\"labels\", \"wb\") as f:\n",
    "    pickle.dump(labels, f, protocol=4)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nx0I6vfg3mVZ"
   },
   "source": [
    "Train the model based on final input arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u006w5ONhu21"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from keras.layers import Input, Dense, Activation, Flatten, Conv2D, Lambda\n",
    "from keras.layers import MaxPooling2D, Dropout\n",
    "from keras.utils import print_summary\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import pickle\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras import backend as K\n",
    "\n",
    "#Function for getting r^2 value\n",
    "def coeff_determination(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred )) \n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) ) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "#Tier 1 model structure\n",
    "def keras_model():\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x/127.5-1.0, input_shape=(66,200,3)))\n",
    "    model.add(Conv2D(24, 5, 5, activation='elu', subsample=(2, 2)))\n",
    "    model.add(Conv2D(36, 5, 5, activation='elu', subsample=(2, 2)))\n",
    "    model.add(Conv2D(48, 5, 5, activation='elu', subsample=(2, 2)))\n",
    "    model.add(Conv2D(64, 3, 3, activation='elu'))\n",
    "    model.add(Conv2D(64, 3, 3, activation='elu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='elu'))\n",
    "    model.add(Dense(50, activation='elu'))\n",
    "    model.add(Dense(10, activation='elu'))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    #compile function with mean squared error loss, learning rate of 0.00001 and metric of r^2\n",
    "    \n",
    "    model.compile(loss='mse', optimizer=Adam(lr=0.00001), metrics=[coeff_determination])\n",
    "    \n",
    "    filepath = \"Capstone.h5\"\n",
    "    #makes sure to save the best model only\n",
    "    checkpoint1 = ModelCheckpoint(filepath, verbose=1, save_best_only=True)\n",
    "    callbacks_list = [checkpoint1]\n",
    "    return model, callbacks_list\n",
    "\n",
    "#loads pickles into arrays\n",
    "def loadFromPickle():\n",
    "    with open(\"features\", \"rb\") as f:\n",
    "        features = np.array(pickle.load(f))\n",
    "    with open(\"labels\", \"rb\") as f:\n",
    "        labels = np.array(pickle.load(f))\n",
    "    return features, labels\n",
    "\n",
    "#flips each image and angle to double dataset\n",
    "def augmentData(features, labels):\n",
    "    features = np.append(features, features[:, :, ::-1], axis=0)\n",
    "    labels = np.append(labels, -labels, axis=0)\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    #load pickles\n",
    "    features, labels = loadFromPickle()\n",
    "    \n",
    "    #Double dataset\n",
    "    features, labels = augmentData(features, labels)\n",
    "    \n",
    "    #Shuffle the data\n",
    "    \n",
    "    features, labels = shuffle(features, labels)\n",
    "    feature = features\n",
    "    \n",
    "    #Split data into training and validation sets\n",
    "    train_x, test_x, train_y, test_y = train_test_split(features, labels, random_state=0,\n",
    "                                                        test_size=0.2)\n",
    "    #reshape inputs arrays\n",
    "    train_x = train_x.reshape(train_x.shape[0], 66, 200, 3)\n",
    "    test_x = test_x.reshape(test_x.shape[0], 66, 200, 3)\n",
    "    \n",
    "    #Fit model with batch size of 13 for 100 epochs\n",
    "    model, callbacks_list = keras_model()\n",
    "    model.fit(train_x, train_y, validation_data=(test_x, test_y), epochs=100, batch_size=13,\n",
    "              callbacks=callbacks_list)\n",
    "    print_summary(model)\n",
    "    \n",
    "    #Save best model\n",
    "    model.save('Capstone.h5')\n",
    "\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24kppjNf3xu6"
   },
   "source": [
    "Predict angles to see if model is working properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oeJbhWD5ukdI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "from google.colab import files\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "\n",
    "#Load previously trained Tier 1 model\n",
    "model = load_model('Autopilot.h5')\n",
    "\n",
    "path2= 'frames'\n",
    "angle = []\n",
    "Z = []\n",
    "y = []\n",
    "\n",
    "#read csv of angles and images into dataframe\n",
    "data = pd.read_csv(\"driving_log.csv\") \n",
    "\n",
    "#Grab individual column data into arrays\n",
    "data_img = np.array(data['Image']) \n",
    "data_img = data_img.reshape(-1, 1)                                                \n",
    "data_angle = np.array(data['Angle'])\n",
    "\n",
    "#Normalize angle values\n",
    "min_max_scaler = preprocessing.MinMaxScaler(feature_range=(-1, 1))              \n",
    "data_norm = (preprocessing.scale(np.float32(data_angle))/10)\n",
    "\n",
    "#prediction function\n",
    "def keras_predict(model, image):\n",
    "    #Process image\n",
    "    processed = keras_process_image(image)\n",
    "    #predict angle based on image\n",
    "    steering_angle = float(model.predict(processed, batch_size=1))\n",
    "    return steering_angle\n",
    "\n",
    "#makes sure image is in correct shape (200x66)\n",
    "def keras_process_image(img):\n",
    "    img = np.array(img, dtype=np.float32)\n",
    "    img = np.reshape(img, (-1, 66, 200, 3))\n",
    "    return img\n",
    "\n",
    "i = 0\n",
    "sum = 0\n",
    "smooth_angle = 0\n",
    "\n",
    "#loops through each image in array\n",
    "for img in data_img:     \n",
    "    \n",
    "    #gets angle and image path\n",
    "    angle = data_angle[i]            \n",
    "    img_string = str(data_img[i,0])\n",
    "    \n",
    "    #reads, crops, and resizes images to 200x66 from 400x300\n",
    "    img_string = img_string[4:]\n",
    "    img_array = cv2.imread('frames/' + img_string, cv2.IMREAD_COLOR)     #creating an array of grayscale imgs\n",
    "    img_array = img_array[80:212,0:400]\n",
    "    img_array = cv2.resize(img_array, (200,66))\n",
    "    \n",
    "    #add predicted angle to array\n",
    "    Z.append(keras_predict(model,img_array))\n",
    "    #add actual angle to array\n",
    "    y.append(angle)\n",
    "    i += 1\n",
    "\n",
    "#combine predicted and actual angle arrays\n",
    "csv = np.column_stack((Z, y))\n",
    "\n",
    "#write arrays to csv file\n",
    "np.savetxt(\"predict.csv\", csv, delimiter=\",\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MVP_Capstone.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
